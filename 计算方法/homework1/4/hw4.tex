\documentclass[a4paper]{book}

\usepackage{geometry}
% make full use of A4 papers
\geometry{margin=1.5cm, vmargin={0pt,1cm}}
\setlength{\topmargin}{-1cm}
\setlength{\paperheight}{29.7cm}
\setlength{\textheight}{25.1cm}

% auto adjust the marginals
\usepackage{marginfix}

\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
%\usepackage{CJKutf8}   % for Chinese characters
\usepackage{ctex}
\usepackage{enumerate}
\usepackage{graphicx}  % for figures
\usepackage{layout}
\usepackage{multicol}  % multiple columns to reduce number of pages
\usepackage{mathrsfs}  
\usepackage{fancyhdr}
\usepackage{subfigure}
\usepackage{tcolorbox}
\usepackage{tikz-cd}
\usepackage{listings}
\usepackage{xcolor} %代码高亮
\usepackage{braket}
\usepackage{algorithm} 
\usepackage{algorithmicx}  
\usepackage{algpseudocode}  
\usepackage{amsmath}  

\floatname{algorithm}{算法}  
\renewcommand{\algorithmicrequire}{\textbf{输入:}}  
\renewcommand{\algorithmicensure}{\textbf{输出:}}  
\renewcommand{\algorithmicrequire}{\textbf{Input : }}
\renewcommand{\algorithmicrequire}{\textbf{Precondition : }}
\renewcommand{\algorithmicensure}{\textbf{Output : }}
\renewcommand{\algorithmicensure}{\textbf{Postcondition : }}
%------------------
% common commands %
%------------------
% differentiation
\newcommand{\gen}[1]{\left\langle #1 \right\rangle}
\newcommand{\dif}{\mathrm{d}}
\newcommand{\difPx}[1]{\frac{\partial #1}{\partial x}}
\newcommand{\difPy}[1]{\frac{\partial #1}{\partial y}}
\newcommand{\Dim}{\mathrm{D}}
\newcommand{\avg}[1]{\left\langle #1 \right\rangle}
\newcommand{\sgn}{\mathrm{sgn}}
\newcommand{\Span}{\mathrm{span}}
\newcommand{\dom}{\mathrm{dom}}
\newcommand{\Arity}{\mathrm{arity}}
\newcommand{\Int}{\mathrm{Int}}
\newcommand{\Ext}{\mathrm{Ext}}
\newcommand{\Cl}{\mathrm{Cl}}
\newcommand{\Fr}{\mathrm{Fr}}
% group is generated by
\newcommand{\grb}[1]{\left\langle #1 \right\rangle}
% rank
\newcommand{\rank}{\mathrm{rank}}
\newcommand{\Iden}{\mathrm{Id}}

% this environment is for solutions of examples and exercises
\newenvironment{solution}%
{\noindent\textbf{Solution.}}%
{\qedhere}
% Define a Solution environment like proof
\makeatletter
\newenvironment{sol}[1][\solname]{\par
  \pushQED{\qed}
  \normalfont \topsep6\p@\@plus6\p@\relax
  \trivlist
  \item[\hskip\labelsep
        \itshape
    #1\@addpunct{.}]\ignorespaces
}{\popQED\endtrivlist\@endpefalse}
\providecommand{\solname}{Solution}
\makeatother
% the following command is for disabling environments
%  so that their contents do not show up in the pdf.
\makeatletter
\newcommand{\voidenvironment}[1]{%
\expandafter\providecommand\csname env@#1@save@env\endcsname{}%
\expandafter\providecommand\csname env@#1@process\endcsname{}%
\@ifundefined{#1}{}{\RenewEnviron{#1}{}}%
}
\makeatother

%---------------------------------------------
% commands specifically for complex analysis %
%---------------------------------------------
% complex conjugate
\newcommand{\ccg}[1]{\overline{#1}}
% the imaginary unit
\newcommand{\ii}{\mathbf{i}}
%\newcommand{\ii}{\boldsymbol{i}}
% the real part
\newcommand{\Rez}{\mathrm{Re}\,}
% the imaginary part
\newcommand{\Imz}{\mathrm{Im}\,}
% punctured complex plane
\newcommand{\pcp}{\mathbb{C}^{\bullet}}
% the principle branch of the logarithm
\newcommand{\Log}{\mathrm{Log}}
% the principle value of a nonzero complex number
\newcommand{\Arg}{\mathrm{Arg}}
\newcommand{\Null}{\mathrm{null}}
\newcommand{\Range}{\mathrm{range}}
\newcommand{\Ker}{\mathrm{ker}}
\newcommand{\Iso}{\mathrm{Iso}}
\newcommand{\Aut}{\mathrm{Aut}}
\newcommand{\ord}{\mathrm{ord}}
\newcommand{\Res}{\mathrm{Res}}
%\newcommand{\GL2R}{\mathrm{GL}(2,\mathbb{R})}
\newcommand{\GL}{\mathrm{GL}}
\newcommand{\SL}{\mathrm{SL}}
\newcommand{\Dist}[2]{\left|{#1}-{#2}\right|}

\newcommand\tbbint{{-\mkern -16mu\int}}
\newcommand\tbint{{\mathchar '26\mkern -14mu\int}}
\newcommand\dbbint{{-\mkern -19mu\int}}
\newcommand\dbint{{\mathchar '26\mkern -18mu\int}}
\newcommand\bint{
{\mathchoice{\dbint}{\tbint}{\tbint}{\tbint}}
}
\newcommand\bbint{
{\mathchoice{\dbbint}{\tbbint}{\tbbint}{\tbbint}}
}





%----------------------------------------
% theorem and theorem-like environments %
%----------------------------------------
\numberwithin{equation}{chapter}
\theoremstyle{definition}

\newtheorem{thm}{Theorem}[chapter]
\newtheorem{axm}[thm]{Axiom}
\newtheorem{alg}[thm]{Algorithm}
\newtheorem{asm}[thm]{Assumption}
\newtheorem{defn}[thm]{Definition}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{rul}[thm]{Rule}
\newtheorem{coro}[thm]{Corollary}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{exm}{Example}[chapter]
\newtheorem{rem}{Remark}[chapter]
\newtheorem{exc}[exm]{Exercise}
\newtheorem{frm}[thm]{Formula}
\newtheorem{ntn}{Notation}
\newtheorem{pro}{Problem}

% for complying with the convention in the textbook
\newtheorem{rmk}[thm]{Remark}


%----------------------
% the end of preamble %
%----------------------

\begin{document}

%\tableofcontents
%\clearpage

\pagestyle{fancy}
%\lhead{Qinghai Zhang}
%\chead{Notes on Algebraic Topology}
%\rhead{Fall 2018}


\setcounter{chapter}{3}
\pagenumbering{arabic}
% \setcounter{page}{0}


% each chapter is factored into a separate file.

\chapter{hw4 12235005 谭焱}
\begin{pro}
    \begin{itemize}
        \item [(a)] Using the composite midpoint quadrature rule, 
        compute the approximate value ofr the integral $\int_0^1 x^3dx$,
        using a mesh size (subinterval length) of $h = 1$ and also
        using a mesh size of $h = 0.5$.

        \item [(b)] Based on the two approximate values computed in part $a$,
        Use Richardson extrapolation to compute a more accurate 
        approximate to the integral.

        \item [(c)] Would you expect the extrapolated result 
        computed in part b to exact in this case? Why?
    \end{itemize}
\end{pro}
\begin{sol}
    \begin{itemize}
        \item [(a)] \begin{align*}
            h = 1, \qquad &M(x^3) = (1 - 0)(1/2)^3) = 1/8 \\
            h = 0.5, \qquad &M(x^3) = 0.5 \times ((1/4)^3 + (3/4)^3) = 7/32
        \end{align*}

        \item [(b)] Since $I(f) = \sum_i f(m_i)h + 
        \frac{f''(m_i)}{24}h^3 + \cdots \Rightarrow 
        F(h) = a_0 + a_1h^2 + \mathcal{O}(h^4) $ means that 
        $p = 2$ and $r = 4$. Using step $1, 0.5$ obtain 
        \[F(0) = F(1) + \frac{F(1) - F(0.5)}{2^{-2} - 1} = 1/4.\]

        \item [(c)] It's not exact that $F(h)$ have $\mathcal{O}(h^4)$
        haven't been eliminated.
    \end{itemize}
\end{sol}

\begin{pro}
    \begin{itemize}
        \item [(a)] If the integrand $f$ is twice continuously
        differentiable and $f''(x) \geq 0$ on $[a, b]$, show that 
        the composite midpoint and trapezoid quadrature rules 
        satisfy the bracketing property 
        \[ M_k(f) \leq \int_a^b f(x) dx \leq T_k(f).\]

        \item [(b)] If the integrand $f$ is convex on $[a, b]$ (see 
        Section 6.2.1), show that the composite midpoint and 
        trapezoid quadrature rules satisfy the bracketing property in
        part $a$.
    \end{itemize}
\end{pro}
\begin{sol}
    \begin{itemize}
        \item [(a)] \begin{align*}
            \int_a^b f(x) dx - M_k(f) &= \sum \int_{a_i}^{a_i + h} f(x) - f(a_i + h /2) dx \\
&= \sum \int_0^{h/2} (f'(\chi) - f'(\xi))t dt  \qquad \chi \in (a_i, a_i + h / 2), \xi \in (a_i + h / 2,
a_i +h) \\
            &\geq 0 
        \end{align*}
        \begin{align*}
            \int_a^b f(x) dx - T_k(f) &= \sum \int_{a_i}^{a_i + h} f(x) - (f(a_i) + f(a_i + h)) /2 dx \\
            &= \sum \int_0^{h/2} (f'(\xi) - f'(\chi))t dt  \qquad \chi \in (a_i, a_i + h / 2), \xi \in (a_i + h / 2,
            a_i +h) \\
            &\leq 0 
        \end{align*}

        \item [(b)] \begin{align*}
            \int_a^b f(x) dx  &= \sum \int_0^{h/2} (f(a_i +t) + f(a_i +h - t) )dt 
            \geq  \sum \int_0^{h/2} f(a_i + h/2) dt = M_k(f)
        \end{align*}
        \begin{align*}
            \int_a^b f(x) dx  &= \sum \int_0^{h} f(a_i +t )dt 
            \leq  \sum \int_0^{h} tf(a_i) + (1-t)f(a_i +h) dt = T_k(f)
        \end{align*}
    \end{itemize}
\end{sol}

\begin{pro}
    Let $p$ be a real polynomial of degree $n$ such that 
    \[ \int_a^b p(x) x^k dx = 0, \qquad k = 0, \ldots, n-1.\]
    \begin{itemize}
        \item [(a)] Show that the $n$ zeros of $p$ are real, simple
        , and lie in the open interval $(a, b)$. (Hint: Consider 
        the polynomial $q_k(x) = (x - x_1)(x - x_2)\cdots (x - x_k)$, 
        where $x_i, i = 1,\ldots, k$, are the roots of $p$ in 
        $[a, b]$.)

        \item [(b)] Show that the $n$-point interpolatory quadrature rule 
        on $[a, b]$ whose nodes are the zeros of $p$ has degree 
        $2n - 1$. (Hint: Consider the quotient and remainder polynomial
        when a given polynomial is divided by $p$.)
    \end{itemize}
\end{pro}
\begin{sol}
    \begin{itemize}
        \item [(a)] Assume $p(x)$ contain $m$ zeros $x_i$ in $(a, b)$ that $m < n$. we have 
        $p(x)(x - x_1)\cdots (x - x_m)$ won't change sign in $(a, b)$, which is 
        conflict with $
            \int_a^bp(x)(x - x_1)\cdots(x - x_m) = \int_a^b p(x) (\sum_p \alpha_p x^p) dx = 0$.

            \item [(b)] Suppose $x_i, w_i$ satisfy 
            \[\sum_i w_i x_i^k = \int_a^b x^k dx, \qquad k = 0,\cdots, n -1\]
            and $x_i$ is zeros of $p(x)$. There is exist $\alpha_k(x), \beta_k(x) \in P_{n-1}(x)$ 
            such that $x^{n +k} = p(x)\alpha_k(x) + \beta_k(x), k < n$, and 
            \begin{align*}
                \int_a^b x^{n + k} dx &= \int_a^b(p(x) \alpha_k(x) + \beta_k(x))dx 
                 = \int_a^b \beta_k(x) dx 
                 \\ &= \sum_i w_i \beta_k(x_i) 
                =\sum_i w_i(p(x_i) \alpha_k(x_i) + \beta_k(x_i)) = \sum_i x_i^{n + k}
            \end{align*}
    \end{itemize}
\end{sol}
\begin{pro}
    The forward difference formula 
    \[ f'(x) \approx \frac{f(x +h ) - f(x)}{h}\]
    and the backward difference formula 
    \[f'(x) \approx \frac{f(x) - f(x -h)}{h}\]
    are both first-order accurate approximations to 
    the first derivative of a function $f: \mathbb{R} \rightarrow 
    \mathbb{R}$. What order accuracy results if we average these 
    two approximations? Support your answer with an error analysis.
\end{pro}
\begin{sol}
    \begin{align*}
        \frac{f(x + h) - f(x)}{h} - f'(x) &= \frac{f''(x)}{2}h - \mathcal{O}(h^2) \\
        \frac{f(x) - f(x - h)}{h} - f'(x) &= - \frac{f''(x)}{2}h - \mathcal{O}(h^2)
    \end{align*}
    So they are first-order accurate. Average result get 
    \begin{align*}
        \frac{f(x + h) - 2f(x) + f(x - h)}{2h} - f'(x) &= \frac{f'''(x)}{6}h^2 - \mathcal{O}(h^3).
    \end{align*}
    Therefore it has second-order accurate.
\end{sol}

\begin{pro}
    Suppose that the first-order accurate, forward difference 
    approximation to the derivative of a function at a given point
    produces the value $-0.8333$ for $h = 0.2$ and the value 
    $-0.9091$ for $h = 0.1$ Use Richardson extrapolation to obtain a better
    approximate value for the derivative.
\end{pro}
\begin{sol}
    Since forward difference formula have $F(h) = a_0 + 
    a_1 h +\mathcal{O}(h^2)$ Which means that $p = 1, r = 2$ in 
    this case. Using step sizes of $h = 0.2$ and $h = 0.1$($ q = 2$),
    we obtain $F(0.2) = -0.8333, F(0.1) = -0.9091$. The 
    extrapolated value is then given by 
    \[F(0) = F(0.2) + \frac{F(0.2) - F(0.1)}{(1/2 - 1)} = 2F(0.1) - F(0.2) = -0.9861.\]
\end{sol}

\begin{pro}
    With an initial value of $y_0=1$ at $t_0=0$
    and a time step of $h=1$,
    compute the approximate solution value $y_1$ at time $t_1 = 1$
    for the ODE $y' = -y$ using each of the following two numerical methods.
    (Your answers should be numbers, not formulas.)
    \begin{itemize}
    \item[(a)]
      Euler's method
  
    \item[(b)]
      Backward Euler method
    \end{itemize}
  \end{pro}
  
  \begin{sol}
    \begin{itemize}
    \item[(a)]
      \begin{displaymath}
        y_1 = y_0+hf(t_0,y_0) = y_0-hy_0 = 1 - 1 = 0.
      \end{displaymath}
  
    \item[(b)]
      \begin{displaymath}
        y_1 = y_0 + hf(t_1, y_1) = y_0-hy_1 \Rightarrow
        y_1 = \frac{y_0}{1+h} = \frac{1}{1+1} = 0.5.
      \end{displaymath}
    \end{itemize}
  \end{sol}

  \begin{pro}
    Consider the IVP
    \begin{displaymath}
      y'' = y
    \end{displaymath}
    for $t\ge 0$,
    with initial values $y(0)=1$ and $y'(0)=2$.
    \begin{itemize}
    \item[(a)]
      Express this second-order ODE as
      an equivalent system of two first-order ODEs.
  
    \item[(b)]
      What are the corresponding initial conditions for the system of
      ODEs in part a?
  
    \item[(c)]
      Are solutions of this system stable?
  
    \item[(d)]
      Perform one step of Euler's method for this ODE system
      using a step size of $h=0.5$.
  
    \item[(e)]
      Is Euler's method stable for this problem using this step size?
  
    \item[(f)]
      Is the backward Euler method stable for this problem
      using this step size?
    \end{itemize}
  \end{pro}
  
  \begin{sol}
    \begin{itemize}
      \item[(a)]
    Define the new unknowns $u_1(t)=y(t)$ and $u_2(t)=y'(t)$,
    then we have
    \begin{displaymath}
      \begin{bmatrix}
        u_1' \\
        u_2'
      \end{bmatrix}
      =
      \begin{bmatrix}
        u_2 \\
        u_1
      \end{bmatrix}
      =
      \begin{bmatrix}
        0 & 1 \\
        1 & 0
      \end{bmatrix}
      \begin{bmatrix}
        u_1 \\
        u_2
      \end{bmatrix}.
    \end{displaymath}
  
  \item[(b)]
    \begin{displaymath}
      \begin{bmatrix}
        u_1(0) \\
        u_2(0)
      \end{bmatrix}
      =
      \begin{bmatrix}
        1 \\
        2
      \end{bmatrix}.
    \end{displaymath}
  
  \item[(c)]
    The eigenvalues of the matrix
    \begin{displaymath}
      A = 
      \begin{bmatrix}
        0 & 1 \\
        1 & 0
      \end{bmatrix}
    \end{displaymath}
    are $1(>0)$ and $-1$,
    thus solutions of this system are unstable.
  
  \item[(d)]
    \begin{displaymath}
      \mathbf{u}_1 = \mathbf{u}_0 + hA\mathbf{u}_0 =
      \begin{bmatrix}
        1 \\ 2
      \end{bmatrix}
      +
      0.5
      \begin{bmatrix}
        2 \\ 1
      \end{bmatrix}
      =
      \begin{bmatrix}
        2 \\ 2.5
      \end{bmatrix}.
    \end{displaymath}
  
  \item[(e)]
    The eigenvalues of the matrix $I+hA = \begin{bmatrix}
        1 & 0.5 \\
        0.5 & 1
      \end{bmatrix}$ are $1.5(> 1)$ and $0.5$,
    therefore,
    Euler's method is unstable for this problem using this step size.
  
  \item[(f)]
    The formula for the backward Euler method is
    \begin{displaymath}
      \mathbf{u}_{n+1} = \mathbf{u}_n + hA\mathbf{u}_{n+1} \Rightarrow
      \mathbf{u}_{n+1} = (I-hA)^{-1}\mathbf{u}_n,
    \end{displaymath}
    the eigenvalues of the matrix $(I-hA)^{-1} = \begin{bmatrix}
        1 & -0.5 \\
        -0.5 & 1
      \end{bmatrix}^{-1}$ are $(1/2)^{-1} = 2(>1)$ and $2/3$,
    therefore,
    backward Euler's method is unstable for this problem using this step size.
  \end{itemize}
  \end{sol}
    
  \begin{pro}
    Applying the midpoint quadrature rule
    on the interval $[t_k, t_{k+1}]$ leads to the implicit
    \emph{midpoint method}
    \begin{displaymath}
      y_{k+1} = y_k + h_kf(t_k+h_k/2, (y_k+y_{k+1})/2)
    \end{displaymath}
    for solving the ODE $y'=f(t,y)$.
    Determine the order of accuracy and
    the stability region of this method.
  \end{pro}

  \begin{sol}
    Applying Taylor's theorem yields
    \begin{align*}
      y(t_{k+1}) &= y(t_k) + h_ky'(t_k) + \frac{h_k^2}{2}y''(t_k) +
      \mathcal{O}(h_k^3); \\
      f\left( t_k+\frac{h_k}{2}, \frac{y(t_k)+y(t_{k+1})}{2}\right) &= f(t_k, y(t_k)) +
                                                               \frac{h_k}{2}f_t(t_k, y(t_k)) +
                                                               \frac{y(t_{k+1})-y(t_k)}{2}f_y(t_k, y(t_k)) + \mathcal{O}(h_k^2) \\
                 &= y'(t_k) + \frac{h_k}{2}\left( f_t(t_k, y(t_k))+f_y(t_k,y(t_k))y'(t_k)\right)
                   + \mathcal{O}(h_k^2) \\
      &= y'(t_k) + \frac{h_k}{2}y''(t_k) + \mathcal{O}(h_k^2).
    \end{align*}
    Therefore
    \begin{align*}
      &y(t_{k+1}) - \left[y(t_k)+h_kf\left( t_k+\frac{h_k}{2}, \frac{y(t_k)+y(t_{k+1})}{2}\right)\right] \\
       &=
        y(t_k) + h_ky'(t_k) + \frac{h_k^2}{2}y''(t_k) +
        \mathcal{O}(h_k^3) \\
        &- \left\{y(t_k) + h_k\left[y'(t_k) + \frac{h_k}{2}y''(t_k) + \mathcal{O}(h_k^2)\right]\right\}
      \\
      &= \mathcal{O}(h_k^3),
    \end{align*}
    which shows that the implicit midpoint method is of order $2$.
  
    To determine the stability of the implicit midpoint method,
    we apply it to the scalar test ODE $y'=\lambda y$,
    obtaining
    \begin{displaymath}
      y_{k+1} = y_k + \frac{\lambda h_k}{2}(y_k+y_{k+1}),
    \end{displaymath}
    which implies that
    \begin{displaymath}
      y_k = \left( \frac{1+h_k\lambda/2}{1-h_k\lambda/2}\right)^ky_0.
    \end{displaymath}
    Thus, the stability region of the implicit midpoint method is
    \begin{displaymath}
      \mathcal{D} = \left\{z\in\mathbb{C}: \left| \frac{1+z}{1-z}\right|<1\right\}.
    \end{displaymath}
  \end{sol}  
  \begin{pro}
    Consider the two-point BVP for the second-order scalar ODE
    \begin{displaymath}
      u'' = u, \quad 0<t<b,
    \end{displaymath}
    with boundary conditions
    \begin{displaymath}
      u(0)=\alpha, \quad u(b) = \beta.
    \end{displaymath}
    \begin{itemize}
    \item[(a)]
      Rewrite the problem as a first-order system of ODEs with
      separated boundary conditions.
  
    \item[(b)]
      Show that the fundamental solution matrix for the resulting linear
      system of ODEs is given by
      \begin{displaymath}
        Y(t) =
        \begin{bmatrix}
          \cosh(t) & \sinh(t) \\
          \sinh(t) & \cosh(t)
        \end{bmatrix}.
      \end{displaymath}
  
    \item[(c)]
      Are the solutions to this ODE stable?
  
    \item[(d)]
      Determine the matrix $Q\equiv B_0Y(0)+B_bY(b)$
      for this problem.
  
    \item[(e)]
      Determine the rescaled solution matrix
      $\Phi(t) = Y(t)Q^{-1}$.
  
    \item[(f)]
      What can you say about the conditioning of $Q$,
      the norm of $\Phi(t)$,
      and the stability of solutions to this BVP as the right endpoint $b$ grows?
    \end{itemize}
  \end{pro}
  
  \begin{sol}
    \begin{itemize}
    \item[(a)]
    Define the new unknowns $y_1(t)=u(t)$ and $y_2(t)=u'(t)$,
    then we have
    \begin{displaymath}
      \begin{bmatrix}
        y_1' \\
        y_2'
      \end{bmatrix}
      =
      \begin{bmatrix}
        y_2 \\
        y_1
      \end{bmatrix}
      =
      \begin{bmatrix}
        0 & 1 \\
        1 & 0
      \end{bmatrix}
      \begin{bmatrix}
        y_1 \\
        y_2
      \end{bmatrix},
    \end{displaymath}
    with separated linear boundary conditions
    \begin{displaymath}
      \begin{bmatrix}
        1 & 0 \\
        0 & 0
      \end{bmatrix}
      \begin{bmatrix}
        y_1(0) \\
        y_2(0)
      \end{bmatrix}
      +
      \begin{bmatrix}
        0 & 0 \\
        1 & 0
      \end{bmatrix}
      \begin{bmatrix}
        y_1(b) \\
        y_2(b)
      \end{bmatrix}
      =
      \begin{bmatrix}
        \alpha \\
        \beta
      \end{bmatrix}.
    \end{displaymath}
  
  \item[(b)]
    Solving $\mathbf{y}'=A\mathbf{y}$ with
    initial condition $\mathbf{y}(0)=\mathbf{e}_1 =
    \begin{bmatrix}
      1 & 0
    \end{bmatrix}^T
    $, we obtain
    $\mathbf{y}(t)=
    \begin{bmatrix}
      \cosh(t) & \sinh(t)
    \end{bmatrix}^T,
    $
    with $\mathbf{y}(0)=\mathbf{e}_2=
    \begin{bmatrix}
      0 & 1
    \end{bmatrix}^T
  $,  $\mathbf{y}(t) =
  \begin{bmatrix}
    \sinh(t) &
    \cosh(t)
  \end{bmatrix}^T
  $.
  Therefore the fundamental solution matrix is
      \begin{displaymath}
        Y(t) =
        \begin{bmatrix}
          \cosh(t) & \sinh(t) \\
          \sinh(t) & \cosh(t)
        \end{bmatrix}.
      \end{displaymath}
  
    \item[(c)]
      The solutions to this ODE are stable,
      since growth in the solution
      % that would otherwise be possible
      is limited by the boundary conditions.
  
    \item[(d)]
      \begin{displaymath}
        Q =
        \begin{bmatrix}
          1 & 0 \\
          0 & 0
        \end{bmatrix}
        \begin{bmatrix}
          1 & 0 \\
          0 & 1
        \end{bmatrix}
        +
        \begin{bmatrix}
          0 & 0 \\
          1 & 0
        \end{bmatrix}
        \begin{bmatrix}
          \cosh(b) & \sinh(b) \\
          \sinh(b) & \cosh(b)
        \end{bmatrix} =
        \begin{bmatrix}
          1 & 0 \\
          \cosh(b) & \sinh(b)
        \end{bmatrix}.
      \end{displaymath}
  
    \item[(e)]
      \begin{align*}
        \Phi(t) &= Y(t)Q^{-1} =
        \begin{bmatrix}
          \cosh(t) & \sinh(t) \\
          \sinh(t) & \cosh(t)
        \end{bmatrix}
                     \begin{bmatrix}
                       1 & 0 \\
                       -\frac{\cosh(b)}{\sinh(b)} & \frac{1}{\sinh(b)}
                     \end{bmatrix} \\
        &= \frac{1}{\sinh(b)}
          \begin{bmatrix}
            \sinh(b-t) & \sinh(t) \\
            -\cosh(b-t) & \cosh(t)
          \end{bmatrix}
      \end{align*}
  
    \item[(f)]
      As $b$ grows,
      the condition number of $Q$ and the norm of $\Phi(t)$ grow as well,
      and the stability of solutions to this BVP decreases.
    \end{itemize}
  \end{sol}

  \begin{pro}
    Consider the two-point BVP
    \begin{displaymath}
      u'' = u^3 + t, \quad a < t < b,
    \end{displaymath}
    with boundary conditions
    \begin{displaymath}
      u(a) = \alpha, \quad u(b) = \beta.
    \end{displaymath}
    To use the shooting method to solve this problem,
    one needs a starting guess for the initial slope $u'(a)$.
    One way to obtain such a starting guess for the initial slope is,
    in effect,
    to do a ``preliminary shooting'' in which we take a single step
    of Euler's method with $h=b-a$.
    \begin{itemize}
    \item[(a)]
      Using this approach,
      write out the resulting algebraic equation for the initial slope.
  
    \item[(b)]
      What starting value for the inital slope results from this approach?
    \end{itemize}
  \end{pro}
  
  \begin{sol}
    \begin{itemize}
    \item[(a)]
      \begin{displaymath}
        u(b) = u(a) + hu'(a) \Rightarrow hu'(a) = u(b)-u(a).
      \end{displaymath}
  
    \item[(b)]
      \begin{displaymath}
        u'(a) = \frac{u(b)-u(a)}{h} = \frac{\beta-\alpha}{b-a}.
      \end{displaymath}
    \end{itemize}
  \end{sol}

\end{document}
